{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare time of different read data methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pptk\n",
    "import datetime\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use numpy ndarray read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15740229, 3)\n",
      "(15740229,)\n",
      "0:03:34.670069\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/arch/Train/1_TR_cloister.txt\"\n",
    "time3 = datetime.datetime.now()\n",
    "data = np.loadtxt(file)\n",
    "scene_points = data[:,0:3].astype('float32')\n",
    "segment_label = data[:,6].astype('int64')\n",
    "time4 = datetime.datetime.now()\n",
    "print(scene_points.shape)\n",
    "print(segment_label.shape)\n",
    "print(time4-time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segment_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1d324092b148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpoint_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscene_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'segment_label' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "choice = np.random.choice(len(segment_label), 1024, replace=True)\n",
    "point_set = scene_points[choice, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use numpy read file + use torch read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15740229, 3])\n",
      "torch.Size([15740229])\n",
      "0:03:52.921357\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/arch/Train/1_TR_cloister.txt\"\n",
    "time1 = datetime.datetime.now()\n",
    "data = np.loadtxt(file)\n",
    "scene_points = torch.from_numpy(data[:, 0:3].astype('float32'))\n",
    "segment_label = torch.from_numpy(data[:,6].astype('int32'))\n",
    "time2 = datetime.datetime.now()\n",
    "print(scene_points.shape)\n",
    "print(segment_label.shape)\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Block - random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2048)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(data, num_sample):\n",
    "    \"\"\" data is in N x ...\n",
    "        we want to keep num_samplexC of them.\n",
    "        if N > num_sample, we will randomly keep num_sample of them.\n",
    "        if N < num_sample, we will randomly duplicate samples.\n",
    "    \"\"\"\n",
    "    N = data.shape[0]\n",
    "    if (N == num_sample):\n",
    "        return data, range(N)\n",
    "    elif (N > num_sample):\n",
    "        sample = np.random.choice(N, num_sample)\n",
    "        return data[sample, ...], sample\n",
    "    else:\n",
    "        sample = np.random.choice(N, num_sample-N)\n",
    "        dup_data = data[sample, ...]\n",
    "        return np.concatenate([data, dup_data], 0), list(range(N))+list(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data_label(data, label, num_sample):\n",
    "    new_data, sample_indices = sample_data(data, num_sample)\n",
    "    new_label = label[sample_indices]\n",
    "    return new_data, new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35296084, 0.72715114, 0.40660786],\n",
       "       [0.79695103, 0.35178304, 0.1483732 ],\n",
       "       [0.02184964, 0.89369391, 0.21384761],\n",
       "       ...,\n",
       "       [0.72761692, 0.63170081, 0.70812537],\n",
       "       [0.58366183, 0.69593253, 0.49909007],\n",
       "       [0.46816175, 0.91908899, 0.4233715 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.random.random((2080,3))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [3],\n",
       "       [5],\n",
       "       [7]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.random.randint(0,10,size=[2080,1])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_data_sampled, block_label_sampled = sample_data_label(data, label, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 3)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "print(block_data_sampled.shape)\n",
    "print(block_label_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.364098  , 0.30908428, 0.63440443],\n",
       "       [0.30548676, 0.40795002, 0.67965822],\n",
       "       [0.52483172, 0.76652738, 0.86369489],\n",
       "       ...,\n",
       "       [0.16839643, 0.47371034, 0.72023846],\n",
       "       [0.05214054, 0.68377316, 0.61206864],\n",
       "       [0.47624035, 0.64036852, 0.56606007]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = np.random.random((2000,3))\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = np.random.randint(0,10,size=[2000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_data2_sampled, block_label2_sampled = sample_data_label(data2, label2, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 3)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "print(block_data2_sampled.shape)\n",
    "print(block_label2_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 2048, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data = np.tile(block_data2_sampled, (93,1,1))\n",
    "current_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "(11, 8, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "file_size = current_data.shape[0]\n",
    "batch_size = 8\n",
    "num_batches = file_size//batch_size\n",
    "all_data = []\n",
    "\n",
    "print(num_batches)\n",
    "for batch_idx in range(num_batches):\n",
    "    #if num_batches == file_size\n",
    "    start_idx = batch_idx*8\n",
    "    end_idx = (batch_idx+1)*8\n",
    "    all_data.append(current_data[start_idx:end_idx, :, :])\n",
    "all_data = np.array(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test block - gen batch to hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\n",
      "[1000, 2048, 3]\n",
      "(1000, 2048, 3)\n",
      "(1000, 2048)\n"
     ]
    }
   ],
   "source": [
    "NUM_POINT = 2048\n",
    "H5_BATCH_SIZE = 1000\n",
    "data_dim = [NUM_POINT, 3]\n",
    "label_dim = [NUM_POINT]\n",
    "\n",
    "batch_data_dim = [H5_BATCH_SIZE] + data_dim\n",
    "batch_label_dim = [H5_BATCH_SIZE] + label_dim\n",
    "h5_batch_data = np.zeros(batch_data_dim, dtype = np.float32)\n",
    "h5_batch_label = np.zeros(batch_label_dim, dtype = np.uint8)\n",
    "buffer_size = 0  # state: record how many samples are currently in buffer\n",
    "h5_index = 0 # state: the next h5 file to save\n",
    "\n",
    "print([H5_BATCH_SIZE])\n",
    "print(batch_data_dim)\n",
    "print(h5_batch_data.shape)\n",
    "print(h5_batch_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "data_size = current_data.shape[0]\n",
    "h5_batch_data[buffer_size:buffer_size+data_size, ...] = current_data\n",
    "buffer_size += data_size\n",
    "\n",
    "print(h5_batch_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.36409798, 0.3090843 , 0.6344044 ],\n",
       "        [0.30548677, 0.40795   , 0.67965823],\n",
       "        [0.5248317 , 0.76652735, 0.8636949 ],\n",
       "        ...,\n",
       "        [0.20645209, 0.01392364, 0.14218394],\n",
       "        [0.22136463, 0.86750555, 0.24099368],\n",
       "        [0.46171084, 0.4232767 , 0.58267117]],\n",
       "\n",
       "       [[0.36409798, 0.3090843 , 0.6344044 ],\n",
       "        [0.30548677, 0.40795   , 0.67965823],\n",
       "        [0.5248317 , 0.76652735, 0.8636949 ],\n",
       "        ...,\n",
       "        [0.20645209, 0.01392364, 0.14218394],\n",
       "        [0.22136463, 0.86750555, 0.24099368],\n",
       "        [0.46171084, 0.4232767 , 0.58267117]],\n",
       "\n",
       "       [[0.36409798, 0.3090843 , 0.6344044 ],\n",
       "        [0.30548677, 0.40795   , 0.67965823],\n",
       "        [0.5248317 , 0.76652735, 0.8636949 ],\n",
       "        ...,\n",
       "        [0.20645209, 0.01392364, 0.14218394],\n",
       "        [0.22136463, 0.86750555, 0.24099368],\n",
       "        [0.46171084, 0.4232767 , 0.58267117]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate hdf5 format (1000, 2048, 10) point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " common.py  'experiment updating.md'   __pycache__   utils\n",
      " data\t     LOG\t\t       README.md     visualization.ipynb\n",
      " datasets    model\t\t       sampling      visualization.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/datasets\n"
     ]
    }
   ],
   "source": [
    "cd datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArCH.py        gen_arch_h5.py  ShapeNetCore.py\n",
      "dataloader.py  __pycache__     synsetoffset2category.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/1_TR_cloister.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/1_TR_cloister.txt and shape: (15740229, 7)\n",
      "block number: 77, 38\n",
      "block data list size: 693\n",
      "(693, 2048, 6), (693, 2048)\n",
      "output file size: (693, 2048, 6), (693, 2048)\n",
      "sample number now: 693now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 0 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/15_OTT_church.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/15_OTT_church.txt and shape: (13302903, 7)\n",
      "block number: 82, 118\n",
      "block data list size: 708\n",
      "(708, 2048, 6), (708, 2048)\n",
      "output file size: (708, 2048, 6), (708, 2048)\n",
      "sample number now: 1401now insert_batch\n",
      "Stored /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch_hdf5_data/train/ply_data_all_0.h5 with size 1000\n",
      "now insert rest data to h5 batch again(401, 2048, 6)\n",
      "now in enough space location, store data in memory\n",
      "finish 1 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/10_SStefano_portico_1.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/10_SStefano_portico_1.txt and shape: (3783699, 7)\n",
      "block number: 50, 43\n",
      "block data list size: 380\n",
      "(380, 2048, 6), (380, 2048)\n",
      "output file size: (380, 2048, 6), (380, 2048)\n",
      "sample number now: 1781now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 2 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/2_TR_church.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/2_TR_church.txt and shape: (20862139, 7)\n",
      "block number: 93, 46\n",
      "block data list size: 641\n",
      "(641, 2048, 6), (641, 2048)\n",
      "output file size: (641, 2048, 6), (641, 2048)\n",
      "sample number now: 2422now insert_batch\n",
      "Stored /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch_hdf5_data/train/ply_data_all_1.h5 with size 1000\n",
      "now insert rest data to h5 batch again(422, 2048, 6)\n",
      "now in enough space location, store data in memory\n",
      "finish 3 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/9_SMV_chapel_10.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/9_SMV_chapel_10.txt and shape: (2193189, 7)\n",
      "block number: 51, 62\n",
      "block data list size: 110\n",
      "(110, 2048, 6), (110, 2048)\n",
      "output file size: (110, 2048, 6), (110, 2048)\n",
      "sample number now: 2532now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 4 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/4_CA_church.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/4_CA_church.txt and shape: (4850807, 7)\n",
      "block number: 92, 36\n",
      "block data list size: 333\n",
      "(333, 2048, 6), (333, 2048)\n",
      "output file size: (333, 2048, 6), (333, 2048)\n",
      "sample number now: 2865now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 5 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/6_SMV_chapel_2to4.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/6_SMV_chapel_2to4.txt and shape: (6326871, 7)\n",
      "block number: 251, 4255\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"gen_arch_h5.py\", line 108, in <module>\n",
      "    stride=1.0)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/utils/common.py\", line 164, in scenetoblocks_wrapper\n",
      "    sampling, sample_num, sample_aug)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/utils/common.py\", line 155, in scenetoblocks_plus\n",
      "    sampling, sample_num, sample_aug)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/utils/common.py\", line 127, in scenetoblocks\n",
      "    xcond = (data[:,0]<=xbeg+block_size) & (data[:,0]>=xbeg)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python gen_arch_h5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "block_size=1.0\n",
    "stride = 1.0\n",
    "data_label_filename = \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/14_TRE_square.txt\"\n",
    "data_label = np.loadtxt(data_label_filename)\n",
    "data = data_label[:,0:6]\n",
    "#get the corner location for our sampling blocks\n",
    "limit = np.amax(data,0)[0:3]\n",
    "\n",
    "#calculate number of blocks and add into block list\n",
    "xbeg_list = []\n",
    "ybeg_list = []\n",
    "\n",
    "num_block_x = int(np.ceil((limit[0] - block_size) / stride)) + 1\n",
    "num_block_y = int(np.ceil((limit[1] - block_size) / stride)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 78)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_block_x, num_block_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/2_TR_church.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/2_TR_church.txt and shape: (20862139, 7)\n",
      "block number: 93, 46\n",
      "block data list size: 641\n",
      "(641, 2048, 6), (641, 2048)\n",
      "output file size: (641, 2048, 6), (641, 2048)\n",
      "sample number now: 641now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 0 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/9_SMV_chapel_10.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/9_SMV_chapel_10.txt and shape: (2193189, 7)\n",
      "block number: 51, 62\n",
      "block data list size: 110\n",
      "(110, 2048, 6), (110, 2048)\n",
      "output file size: (110, 2048, 6), (110, 2048)\n",
      "sample number now: 751now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 1 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/4_CA_church.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/4_CA_church.txt and shape: (4850807, 7)\n",
      "block number: 92, 36\n",
      "block data list size: 333\n",
      "(333, 2048, 6), (333, 2048)\n",
      "output file size: (333, 2048, 6), (333, 2048)\n",
      "sample number now: 1084now insert_batch\n",
      "Stored /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch_hdf5_data/train/ply_data_all_2.h5 with size 1000\n",
      "now insert rest data to h5 batch again(84, 2048, 6)\n",
      "now in enough space location, store data in memory\n",
      "finish 2 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/12_KAS_pavillion_1.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/12_KAS_pavillion_1.txt and shape: (598380, 7)\n",
      "block number: 84, 57\n",
      "block data list size: 93\n",
      "(93, 2048, 6), (93, 2048)\n",
      "output file size: (93, 2048, 6), (93, 2048)\n",
      "sample number now: 1177now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 3 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/13_KAS_pavillion_2.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/13_KAS_pavillion_2.txt and shape: (325818, 7)\n",
      "block number: 84, 44\n",
      "block data list size: 48\n",
      "(48, 2048, 6), (48, 2048)\n",
      "output file size: (48, 2048, 6), (48, 2048)\n",
      "sample number now: 1225now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 4 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/14_TRE_square.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/14_TRE_square.txt and shape: (9409239, 7)\n",
      "block number: 62, 78\n",
      "block data list size: 450\n",
      "(450, 2048, 6), (450, 2048)\n",
      "output file size: (450, 2048, 6), (450, 2048)\n",
      "sample number now: 1675now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 5 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/11_SStefano_portico_2.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/11_SStefano_portico_2.txt and shape: (10047392, 7)\n",
      "block number: 47, 71\n",
      "block data list size: 11\n",
      "(11, 2048, 6), (11, 2048)\n",
      "output file size: (11, 2048, 6), (11, 2048)\n",
      "sample number now: 1686now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "Stored /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch_hdf5_data/train/ply_data_all_3.h5 with size 686\n",
      "in last batch!\n",
      "finish 6 times\n",
      "Total samples: 1686\n"
     ]
    }
   ],
   "source": [
    "!python gen_arch_h5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
