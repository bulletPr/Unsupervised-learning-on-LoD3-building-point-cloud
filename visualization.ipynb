{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare time of different read data methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pptk\n",
    "import datetime\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use numpy ndarray read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15740229, 3)\n",
      "(15740229,)\n",
      "0:03:34.670069\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/arch/Train/1_TR_cloister.txt\"\n",
    "time3 = datetime.datetime.now()\n",
    "data = np.loadtxt(file)\n",
    "scene_points = data[:,0:3].astype('float32')\n",
    "segment_label = data[:,6].astype('int64')\n",
    "time4 = datetime.datetime.now()\n",
    "print(scene_points.shape)\n",
    "print(segment_label.shape)\n",
    "print(time4-time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segment_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1d324092b148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpoint_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscene_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'segment_label' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "choice = np.random.choice(len(segment_label), 1024, replace=True)\n",
    "point_set = scene_points[choice, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use numpy read file + use torch read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15740229, 3])\n",
      "torch.Size([15740229])\n",
      "0:03:52.921357\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/arch/Train/1_TR_cloister.txt\"\n",
    "time1 = datetime.datetime.now()\n",
    "data = np.loadtxt(file)\n",
    "scene_points = torch.from_numpy(data[:, 0:3].astype('float32'))\n",
    "segment_label = torch.from_numpy(data[:,6].astype('int32'))\n",
    "time2 = datetime.datetime.now()\n",
    "print(scene_points.shape)\n",
    "print(segment_label.shape)\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Block - random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2048)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(data, num_sample):\n",
    "    \"\"\" data is in N x ...\n",
    "        we want to keep num_samplexC of them.\n",
    "        if N > num_sample, we will randomly keep num_sample of them.\n",
    "        if N < num_sample, we will randomly duplicate samples.\n",
    "    \"\"\"\n",
    "    N = data.shape[0]\n",
    "    if (N == num_sample):\n",
    "        return data, range(N)\n",
    "    elif (N > num_sample):\n",
    "        sample = np.random.choice(N, num_sample)\n",
    "        return data[sample, ...], sample\n",
    "    else:\n",
    "        sample = np.random.choice(N, num_sample-N)\n",
    "        dup_data = data[sample, ...]\n",
    "        return np.concatenate([data, dup_data], 0), list(range(N))+list(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data_label(data, label, num_sample):\n",
    "    new_data, sample_indices = sample_data(data, num_sample)\n",
    "    new_label = label[sample_indices]\n",
    "    return new_data, new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35296084, 0.72715114, 0.40660786],\n",
       "       [0.79695103, 0.35178304, 0.1483732 ],\n",
       "       [0.02184964, 0.89369391, 0.21384761],\n",
       "       ...,\n",
       "       [0.72761692, 0.63170081, 0.70812537],\n",
       "       [0.58366183, 0.69593253, 0.49909007],\n",
       "       [0.46816175, 0.91908899, 0.4233715 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.random.random((2080,3))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [3],\n",
       "       [5],\n",
       "       [7]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.random.randint(0,10,size=[2080,1])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_data_sampled, block_label_sampled = sample_data_label(data, label, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 3)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "print(block_data_sampled.shape)\n",
    "print(block_label_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.364098  , 0.30908428, 0.63440443],\n",
       "       [0.30548676, 0.40795002, 0.67965822],\n",
       "       [0.52483172, 0.76652738, 0.86369489],\n",
       "       ...,\n",
       "       [0.16839643, 0.47371034, 0.72023846],\n",
       "       [0.05214054, 0.68377316, 0.61206864],\n",
       "       [0.47624035, 0.64036852, 0.56606007]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = np.random.random((2000,3))\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = np.random.randint(0,10,size=[2000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_data2_sampled, block_label2_sampled = sample_data_label(data2, label2, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 3)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "print(block_data2_sampled.shape)\n",
    "print(block_label2_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 2048, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data = np.tile(block_data2_sampled, (93,1,1))\n",
    "current_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "(11, 8, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "file_size = current_data.shape[0]\n",
    "batch_size = 8\n",
    "num_batches = file_size//batch_size\n",
    "all_data = []\n",
    "\n",
    "print(num_batches)\n",
    "for batch_idx in range(num_batches):\n",
    "    #if num_batches == file_size\n",
    "    start_idx = batch_idx*8\n",
    "    end_idx = (batch_idx+1)*8\n",
    "    all_data.append(current_data[start_idx:end_idx, :, :])\n",
    "all_data = np.array(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test block - gen batch to hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\n",
      "[1000, 2048, 3]\n",
      "(1000, 2048, 3)\n",
      "(1000, 2048)\n"
     ]
    }
   ],
   "source": [
    "NUM_POINT = 2048\n",
    "H5_BATCH_SIZE = 1000\n",
    "data_dim = [NUM_POINT, 3]\n",
    "label_dim = [NUM_POINT]\n",
    "\n",
    "batch_data_dim = [H5_BATCH_SIZE] + data_dim\n",
    "batch_label_dim = [H5_BATCH_SIZE] + label_dim\n",
    "h5_batch_data = np.zeros(batch_data_dim, dtype = np.float32)\n",
    "h5_batch_label = np.zeros(batch_label_dim, dtype = np.uint8)\n",
    "buffer_size = 0  # state: record how many samples are currently in buffer\n",
    "h5_index = 0 # state: the next h5 file to save\n",
    "\n",
    "print([H5_BATCH_SIZE])\n",
    "print(batch_data_dim)\n",
    "print(h5_batch_data.shape)\n",
    "print(h5_batch_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "data_size = current_data.shape[0]\n",
    "h5_batch_data[buffer_size:buffer_size+data_size, ...] = current_data\n",
    "buffer_size += data_size\n",
    "\n",
    "print(h5_batch_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.36409798, 0.3090843 , 0.6344044 ],\n",
       "        [0.30548677, 0.40795   , 0.67965823],\n",
       "        [0.5248317 , 0.76652735, 0.8636949 ],\n",
       "        ...,\n",
       "        [0.20645209, 0.01392364, 0.14218394],\n",
       "        [0.22136463, 0.86750555, 0.24099368],\n",
       "        [0.46171084, 0.4232767 , 0.58267117]],\n",
       "\n",
       "       [[0.36409798, 0.3090843 , 0.6344044 ],\n",
       "        [0.30548677, 0.40795   , 0.67965823],\n",
       "        [0.5248317 , 0.76652735, 0.8636949 ],\n",
       "        ...,\n",
       "        [0.20645209, 0.01392364, 0.14218394],\n",
       "        [0.22136463, 0.86750555, 0.24099368],\n",
       "        [0.46171084, 0.4232767 , 0.58267117]],\n",
       "\n",
       "       [[0.36409798, 0.3090843 , 0.6344044 ],\n",
       "        [0.30548677, 0.40795   , 0.67965823],\n",
       "        [0.5248317 , 0.76652735, 0.8636949 ],\n",
       "        ...,\n",
       "        [0.20645209, 0.01392364, 0.14218394],\n",
       "        [0.22136463, 0.86750555, 0.24099368],\n",
       "        [0.46171084, 0.4232767 , 0.58267117]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
