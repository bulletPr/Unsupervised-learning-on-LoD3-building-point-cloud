{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare time of different read data methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pptk\n",
    "import datetime\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use numpy ndarray read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15740229, 3)\n",
      "(15740229,)\n",
      "0:03:34.670069\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/arch/Train/1_TR_cloister.txt\"\n",
    "time3 = datetime.datetime.now()\n",
    "data = np.loadtxt(file)\n",
    "scene_points = data[:,0:3].astype('float32')\n",
    "segment_label = data[:,6].astype('int64')\n",
    "time4 = datetime.datetime.now()\n",
    "print(scene_points.shape)\n",
    "print(segment_label.shape)\n",
    "print(time4-time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segment_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1d324092b148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpoint_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscene_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'segment_label' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "choice = np.random.choice(len(segment_label), 1024, replace=True)\n",
    "point_set = scene_points[choice, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use numpy read file + use torch read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15740229, 3])\n",
      "torch.Size([15740229])\n",
      "0:03:52.921357\n"
     ]
    }
   ],
   "source": [
    "file = \"./data/arch/Train/1_TR_cloister.txt\"\n",
    "time1 = datetime.datetime.now()\n",
    "data = np.loadtxt(file)\n",
    "scene_points = torch.from_numpy(data[:, 0:3].astype('float32'))\n",
    "segment_label = torch.from_numpy(data[:,6].astype('int32'))\n",
    "time2 = datetime.datetime.now()\n",
    "print(scene_points.shape)\n",
    "print(segment_label.shape)\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Block - random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2048)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(data, num_sample):\n",
    "    \"\"\" data is in N x ...\n",
    "        we want to keep num_samplexC of them.\n",
    "        if N > num_sample, we will randomly keep num_sample of them.\n",
    "        if N < num_sample, we will randomly duplicate samples.\n",
    "    \"\"\"\n",
    "    N = data.shape[0]\n",
    "    if (N == num_sample):\n",
    "        return data, range(N)\n",
    "    elif (N > num_sample):\n",
    "        sample = np.random.choice(N, num_sample)\n",
    "        return data[sample, ...], sample\n",
    "    else:\n",
    "        sample = np.random.choice(N, num_sample-N)\n",
    "        dup_data = data[sample, ...]\n",
    "        return np.concatenate([data, dup_data], 0), list(range(N))+list(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data_label(data, label, num_sample):\n",
    "    new_data, sample_indices = sample_data(data, num_sample)\n",
    "    new_label = label[sample_indices]\n",
    "    return new_data, new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35296084, 0.72715114, 0.40660786],\n",
       "       [0.79695103, 0.35178304, 0.1483732 ],\n",
       "       [0.02184964, 0.89369391, 0.21384761],\n",
       "       ...,\n",
       "       [0.72761692, 0.63170081, 0.70812537],\n",
       "       [0.58366183, 0.69593253, 0.49909007],\n",
       "       [0.46816175, 0.91908899, 0.4233715 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.random.random((2080,3))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [3],\n",
       "       [5],\n",
       "       [7]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.random.randint(0,10,size=[2080,1])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_data_sampled, block_label_sampled = sample_data_label(data, label, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 3)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "print(block_data_sampled.shape)\n",
    "print(block_label_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.364098  , 0.30908428, 0.63440443],\n",
       "       [0.30548676, 0.40795002, 0.67965822],\n",
       "       [0.52483172, 0.76652738, 0.86369489],\n",
       "       ...,\n",
       "       [0.16839643, 0.47371034, 0.72023846],\n",
       "       [0.05214054, 0.68377316, 0.61206864],\n",
       "       [0.47624035, 0.64036852, 0.56606007]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = np.random.random((2000,3))\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = np.random.randint(0,10,size=[2000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_data2_sampled, block_label2_sampled = sample_data_label(data2, label2, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 3)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "print(block_data2_sampled.shape)\n",
    "print(block_label2_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 2048, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data = np.tile(block_data2_sampled, (93,1,1))\n",
    "current_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "(11, 8, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "file_size = current_data.shape[0]\n",
    "batch_size = 8\n",
    "num_batches = file_size//batch_size\n",
    "all_data = []\n",
    "\n",
    "print(num_batches)\n",
    "for batch_idx in range(num_batches):\n",
    "    #if num_batches == file_size\n",
    "    start_idx = batch_idx*8\n",
    "    end_idx = (batch_idx+1)*8\n",
    "    all_data.append(current_data[start_idx:end_idx, :, :])\n",
    "all_data = np.array(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test block - gen batch to hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\n",
      "[1000, 2048, 3]\n",
      "(1000, 2048, 3)\n",
      "(1000, 2048)\n"
     ]
    }
   ],
   "source": [
    "NUM_POINT = 2048\n",
    "H5_BATCH_SIZE = 1000\n",
    "data_dim = [NUM_POINT, 3]\n",
    "label_dim = [NUM_POINT]\n",
    "\n",
    "batch_data_dim = [H5_BATCH_SIZE] + data_dim\n",
    "batch_label_dim = [H5_BATCH_SIZE] + label_dim\n",
    "h5_batch_data = np.zeros(batch_data_dim, dtype = np.float32)\n",
    "h5_batch_label = np.zeros(batch_label_dim, dtype = np.uint8)\n",
    "buffer_size = 0  # state: record how many samples are currently in buffer\n",
    "h5_index = 0 # state: the next h5 file to save\n",
    "\n",
    "print([H5_BATCH_SIZE])\n",
    "print(batch_data_dim)\n",
    "print(h5_batch_data.shape)\n",
    "print(h5_batch_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "data_size = current_data.shape[0]\n",
    "h5_batch_data[buffer_size:buffer_size+data_size, ...] = current_data\n",
    "buffer_size += data_size\n",
    "\n",
    "print(h5_batch_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.36409798, 0.3090843 , 0.6344044 ],\n",
       "        [0.30548677, 0.40795   , 0.67965823],\n",
       "        [0.5248317 , 0.76652735, 0.8636949 ],\n",
       "        ...,\n",
       "        [0.20645209, 0.01392364, 0.14218394],\n",
       "        [0.22136463, 0.86750555, 0.24099368],\n",
       "        [0.46171084, 0.4232767 , 0.58267117]],\n",
       "\n",
       "       [[0.36409798, 0.3090843 , 0.6344044 ],\n",
       "        [0.30548677, 0.40795   , 0.67965823],\n",
       "        [0.5248317 , 0.76652735, 0.8636949 ],\n",
       "        ...,\n",
       "        [0.20645209, 0.01392364, 0.14218394],\n",
       "        [0.22136463, 0.86750555, 0.24099368],\n",
       "        [0.46171084, 0.4232767 , 0.58267117]],\n",
       "\n",
       "       [[0.36409798, 0.3090843 , 0.6344044 ],\n",
       "        [0.30548677, 0.40795   , 0.67965823],\n",
       "        [0.5248317 , 0.76652735, 0.8636949 ],\n",
       "        ...,\n",
       "        [0.20645209, 0.01392364, 0.14218394],\n",
       "        [0.22136463, 0.86750555, 0.24099368],\n",
       "        [0.46171084, 0.4232767 , 0.58267117]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate hdf5 format (1000, 2048, 10) point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " common.py  'experiment updating.md'   __pycache__   utils\n",
      " data\t     LOG\t\t       README.md     visualization.ipynb\n",
      " datasets    model\t\t       sampling      visualization.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/datasets\n"
     ]
    }
   ],
   "source": [
    "cd datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArCH.py        gen_arch_h5.py  ShapeNetCore.py\n",
      "dataloader.py  __pycache__     synsetoffset2category.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/1_TR_cloister.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/1_TR_cloister.txt and shape: (15740229, 7)\n",
      "block number: 77, 38\n",
      "block data list size: 693\n",
      "(693, 2048, 6), (693, 2048)\n",
      "output file size: (693, 2048, 6), (693, 2048)\n",
      "sample number now: 693now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 0 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/15_OTT_church.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/15_OTT_church.txt and shape: (13302903, 7)\n",
      "block number: 82, 118\n",
      "block data list size: 708\n",
      "(708, 2048, 6), (708, 2048)\n",
      "output file size: (708, 2048, 6), (708, 2048)\n",
      "sample number now: 1401now insert_batch\n",
      "Stored /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch_hdf5_data/train/ply_data_all_0.h5 with size 1000\n",
      "now insert rest data to h5 batch again(401, 2048, 6)\n",
      "now in enough space location, store data in memory\n",
      "finish 1 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/10_SStefano_portico_1.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/10_SStefano_portico_1.txt and shape: (3783699, 7)\n",
      "block number: 50, 43\n",
      "block data list size: 380\n",
      "(380, 2048, 6), (380, 2048)\n",
      "output file size: (380, 2048, 6), (380, 2048)\n",
      "sample number now: 1781now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 2 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/2_TR_church.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/2_TR_church.txt and shape: (20862139, 7)\n",
      "block number: 93, 46\n",
      "block data list size: 641\n",
      "(641, 2048, 6), (641, 2048)\n",
      "output file size: (641, 2048, 6), (641, 2048)\n",
      "sample number now: 2422now insert_batch\n",
      "Stored /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch_hdf5_data/train/ply_data_all_1.h5 with size 1000\n",
      "now insert rest data to h5 batch again(422, 2048, 6)\n",
      "now in enough space location, store data in memory\n",
      "finish 3 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/9_SMV_chapel_10.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/9_SMV_chapel_10.txt and shape: (2193189, 7)\n",
      "block number: 51, 62\n",
      "block data list size: 110\n",
      "(110, 2048, 6), (110, 2048)\n",
      "output file size: (110, 2048, 6), (110, 2048)\n",
      "sample number now: 2532now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 4 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/4_CA_church.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/4_CA_church.txt and shape: (4850807, 7)\n",
      "block number: 92, 36\n",
      "block data list size: 333\n",
      "(333, 2048, 6), (333, 2048)\n",
      "output file size: (333, 2048, 6), (333, 2048)\n",
      "sample number now: 2865now insert_batch\n",
      "now in enough space location, store data in memory\n",
      "finish 5 times\n",
      "input file: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/6_SMV_chapel_2to4.txt\n",
      "input scene: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/6_SMV_chapel_2to4.txt and shape: (6326871, 7)\n",
      "block number: 251, 4255\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"gen_arch_h5.py\", line 108, in <module>\n",
      "    stride=1.0)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/utils/common.py\", line 164, in scenetoblocks_wrapper\n",
      "    sampling, sample_num, sample_aug)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/utils/common.py\", line 155, in scenetoblocks_plus\n",
      "    sampling, sample_num, sample_aug)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/utils/common.py\", line 127, in scenetoblocks\n",
      "    xcond = (data[:,0]<=xbeg+block_size) & (data[:,0]>=xbeg)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python gen_arch_h5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "block_size=1.0\n",
    "stride = 1.0\n",
    "data_label_filename = \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/Train1/14_TRE_square.txt\"\n",
    "data_label = np.loadtxt(data_label_filename)\n",
    "data = data_label[:,0:6]\n",
    "#get the corner location for our sampling blocks\n",
    "limit = np.amax(data,0)[0:3]\n",
    "\n",
    "#calculate number of blocks and add into block list\n",
    "xbeg_list = []\n",
    "ybeg_list = []\n",
    "\n",
    "num_block_x = int(np.ceil((limit[0] - block_size) / stride)) + 1\n",
    "num_block_y = int(np.ceil((limit[1] - block_size) / stride)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 78)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_block_x, num_block_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'gen_arch_h5.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python gen_arch_h5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test PointCNN point clouds split algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-28 17:20:54.410138-Loading ./data/arch/Test1/A_SMG_portico.txt...\n",
      "[('zero', 0.0), ('half', 1.0)]\n",
      "2020-10-28 17:24:46.661784-Computing block id of 17798012 points...\n",
      "xyz_min: [[ 69.39041138 103.79975128 374.05963135]]\n",
      "xyz_max: [[133.0887146  156.79910278 385.18084717]]\n",
      "11.121215819999975\n",
      "block_size: (2.0, 2.0, 22.24243163999995)\n",
      "[[29 22  0]\n",
      " [29 22  0]\n",
      " [29 22  0]\n",
      " ...\n",
      " [30 24  0]\n",
      " [30 24  0]\n",
      " [30 24  0]]\n",
      "2020-10-28 17:24:48.781681-Collecting points belong to each block...\n",
      "[[ 0  3  0]\n",
      " [ 0  4  0]\n",
      " [ 0  5  0]\n",
      " [ 0  6  0]\n",
      " [ 1  2  0]\n",
      " [ 1  3  0]\n",
      " [ 1  4  0]\n",
      " [ 1  5  0]\n",
      " [ 1  6  0]\n",
      " [ 1  7  0]\n",
      " [ 2  2  0]\n",
      " [ 2  3  0]\n",
      " [ 2  4  0]\n",
      " [ 2  5  0]\n",
      " [ 2  6  0]\n",
      " [ 2  7  0]\n",
      " [ 2  8  0]\n",
      " [ 2  9  0]\n",
      " [ 3  1  0]\n",
      " [ 3  2  0]\n",
      " [ 3  3  0]\n",
      " [ 3  4  0]\n",
      " [ 3  5  0]\n",
      " [ 3  6  0]\n",
      " [ 3  7  0]\n",
      " [ 3  8  0]\n",
      " [ 3  9  0]\n",
      " [ 3 10  0]\n",
      " [ 4  0  0]\n",
      " [ 4  1  0]\n",
      " [ 4  2  0]\n",
      " [ 4  3  0]\n",
      " [ 4  4  0]\n",
      " [ 4  5  0]\n",
      " [ 4  6  0]\n",
      " [ 4  7  0]\n",
      " [ 4  8  0]\n",
      " [ 4  9  0]\n",
      " [ 4 10  0]\n",
      " [ 4 11  0]\n",
      " [ 4 12  0]\n",
      " [ 5  0  0]\n",
      " [ 5  1  0]\n",
      " [ 5  2  0]\n",
      " [ 5  3  0]\n",
      " [ 5  4  0]\n",
      " [ 5  5  0]\n",
      " [ 5  6  0]\n",
      " [ 5  7  0]\n",
      " [ 5  8  0]\n",
      " [ 5  9  0]\n",
      " [ 5 10  0]\n",
      " [ 5 11  0]\n",
      " [ 5 12  0]\n",
      " [ 5 13  0]\n",
      " [ 6  0  0]\n",
      " [ 6  1  0]\n",
      " [ 6  2  0]\n",
      " [ 6  3  0]\n",
      " [ 6  4  0]\n",
      " [ 6  5  0]\n",
      " [ 6  6  0]\n",
      " [ 6  7  0]\n",
      " [ 6  8  0]\n",
      " [ 6  9  0]\n",
      " [ 6 10  0]\n",
      " [ 6 11  0]\n",
      " [ 6 12  0]\n",
      " [ 7  0  0]\n",
      " [ 7  1  0]\n",
      " [ 7  2  0]\n",
      " [ 7  3  0]\n",
      " [ 7  4  0]\n",
      " [ 7  5  0]\n",
      " [ 7  6  0]\n",
      " [ 7  7  0]\n",
      " [ 7  8  0]\n",
      " [ 7  9  0]\n",
      " [ 7 10  0]\n",
      " [ 7 11  0]\n",
      " [ 7 12  0]\n",
      " [ 8  0  0]\n",
      " [ 8  1  0]\n",
      " [ 8  2  0]\n",
      " [ 8  3  0]\n",
      " [ 8  4  0]\n",
      " [ 8  5  0]\n",
      " [ 8  6  0]\n",
      " [ 8  7  0]\n",
      " [ 8  8  0]\n",
      " [ 8  9  0]\n",
      " [ 8 10  0]\n",
      " [ 8 11  0]\n",
      " [ 9  1  0]\n",
      " [ 9  2  0]\n",
      " [ 9  3  0]\n",
      " [ 9  4  0]\n",
      " [ 9  5  0]\n",
      " [ 9  6  0]\n",
      " [ 9  7  0]\n",
      " [ 9  8  0]\n",
      " [ 9  9  0]\n",
      " [ 9 10  0]\n",
      " [10  2  0]\n",
      " [10  3  0]\n",
      " [10  4  0]\n",
      " [10  5  0]\n",
      " [10  6  0]\n",
      " [10  7  0]\n",
      " [10  8  0]\n",
      " [10  9  0]\n",
      " [10 10  0]\n",
      " [11  2  0]\n",
      " [11  3  0]\n",
      " [11  4  0]\n",
      " [11  5  0]\n",
      " [11  6  0]\n",
      " [11  7  0]\n",
      " [11  8  0]\n",
      " [11  9  0]\n",
      " [12  2  0]\n",
      " [12  3  0]\n",
      " [12  4  0]\n",
      " [12  5  0]\n",
      " [12  6  0]\n",
      " [12  7  0]\n",
      " [12  8  0]\n",
      " [13  2  0]\n",
      " [13  3  0]\n",
      " [13  4  0]\n",
      " [13  5  0]\n",
      " [13  6  0]\n",
      " [13  7  0]\n",
      " [13  8  0]\n",
      " [14  3  0]\n",
      " [14  4  0]\n",
      " [14  5  0]\n",
      " [14  6  0]\n",
      " [14  7  0]\n",
      " [14  8  0]\n",
      " [14  9  0]\n",
      " [15  5  0]\n",
      " [15  6  0]\n",
      " [15  7  0]\n",
      " [15  8  0]\n",
      " [15  9  0]\n",
      " [15 10  0]\n",
      " [16  6  0]\n",
      " [16  7  0]\n",
      " [16  8  0]\n",
      " [16  9  0]\n",
      " [16 10  0]\n",
      " [16 11  0]\n",
      " [17  7  0]\n",
      " [17  8  0]\n",
      " [17  9  0]\n",
      " [17 10  0]\n",
      " [17 11  0]\n",
      " [17 12  0]\n",
      " [17 13  0]\n",
      " [18  8  0]\n",
      " [18  9  0]\n",
      " [18 10  0]\n",
      " [18 11  0]\n",
      " [18 12  0]\n",
      " [18 13  0]\n",
      " [18 14  0]\n",
      " [19  9  0]\n",
      " [19 10  0]\n",
      " [19 11  0]\n",
      " [19 12  0]\n",
      " [19 13  0]\n",
      " [19 14  0]\n",
      " [19 15  0]\n",
      " [20 10  0]\n",
      " [20 11  0]\n",
      " [20 12  0]\n",
      " [20 13  0]\n",
      " [20 14  0]\n",
      " [20 15  0]\n",
      " [20 16  0]\n",
      " [21 11  0]\n",
      " [21 12  0]\n",
      " [21 13  0]\n",
      " [21 14  0]\n",
      " [21 15  0]\n",
      " [21 16  0]\n",
      " [21 17  0]\n",
      " [22 13  0]\n",
      " [22 14  0]\n",
      " [22 15  0]\n",
      " [22 16  0]\n",
      " [22 17  0]\n",
      " [22 18  0]\n",
      " [22 19  0]\n",
      " [23 14  0]\n",
      " [23 15  0]\n",
      " [23 16  0]\n",
      " [23 17  0]\n",
      " [23 18  0]\n",
      " [23 19  0]\n",
      " [23 20  0]\n",
      " [24 15  0]\n",
      " [24 16  0]\n",
      " [24 17  0]\n",
      " [24 18  0]\n",
      " [24 19  0]\n",
      " [24 20  0]\n",
      " [24 21  0]\n",
      " [25 16  0]\n",
      " [25 17  0]\n",
      " [25 18  0]\n",
      " [25 19  0]\n",
      " [25 20  0]\n",
      " [25 21  0]\n",
      " [25 22  0]\n",
      " [26 17  0]\n",
      " [26 18  0]\n",
      " [26 19  0]\n",
      " [26 20  0]\n",
      " [26 21  0]\n",
      " [26 22  0]\n",
      " [26 23  0]\n",
      " [27 18  0]\n",
      " [27 19  0]\n",
      " [27 20  0]\n",
      " [27 21  0]\n",
      " [27 22  0]\n",
      " [27 23  0]\n",
      " [27 24  0]\n",
      " [27 25  0]\n",
      " [28 20  0]\n",
      " [28 21  0]\n",
      " [28 22  0]\n",
      " [28 23  0]\n",
      " [28 24  0]\n",
      " [28 25  0]\n",
      " [28 26  0]\n",
      " [29 19  0]\n",
      " [29 20  0]\n",
      " [29 21  0]\n",
      " [29 22  0]\n",
      " [29 23  0]\n",
      " [29 24  0]\n",
      " [29 25  0]\n",
      " [29 26  0]\n",
      " [30 18  0]\n",
      " [30 19  0]\n",
      " [30 20  0]\n",
      " [30 21  0]\n",
      " [30 22  0]\n",
      " [30 23  0]\n",
      " [30 24  0]\n",
      " [30 25  0]\n",
      " [31 19  0]\n",
      " [31 20  0]\n",
      " [31 23  0]\n",
      " [31 24  0]\n",
      " [31 25  0]]\n",
      "[241 241 241 ... 252 252 252]\n",
      "[  2428  18423   7418   2196    401  40303  55579  21058  26557  16404\n",
      "  10494  81835  20788  60572  71459  81683  46702   1551   1815  77539\n",
      "  19824  17955  18019  59301  64245  23218  41881   9735     42  31143\n",
      "  42799  18653  18035  22123  77774  18607  19011  19308  20214  10006\n",
      "    441   8526  46274  18204  18772  19084  69493  22253  19347  19216\n",
      "  18979  18375  18185  21106    891  55196  17909  18432  18967  48239\n",
      "  36469  18920  19793  19847  19839  20112  25232  25165  48864  94338\n",
      "  33014  28615  68628  17275  18799  20502  20332  20471  19370  37739\n",
      "    937   1211  29065  55138  88072  17107  17364  19964  21553  22744\n",
      "  20002  32725   7311     81 128217  49277  17839  17234  22782  21420\n",
      "  19462  37885  33335  28537 128123  41035  49149  23473  18397  18738\n",
      "  18319    945   6183  15438 142519  41086  19009  21416  24731   5273\n",
      "  52544  64756  62091 136022  67276  39844  33369    138  93724  72133\n",
      "  77380 155843 150766   6392     10  93376 101624  89935 171063 215417\n",
      "  19015  37622 138755  90888 142276 219939  25252  25239 151357  85623\n",
      " 111587 227899  38271  13869 139562  88794  71868 193124  50909    197\n",
      "   7716 102201 116049  74075 167710  92818    769   1915 105187 104041\n",
      "  87713 185063 162689   4835    368 118691 107798  92483 157178 193025\n",
      "  30388      9  86177 103250  88430 148659 215618  43349  31455 152803\n",
      "  97800 134151 233428  54227      5  21159 171974 120274 118707 238741\n",
      "  72676     55  10629 142186 149398 106320 187821 102900    689   2149\n",
      "  96421 157626 110780 223455 156294   2672    137  86635 131015 119544\n",
      " 209450 205852  19770      7  94448 127781 114670 166598 260781 141145\n",
      "    310  52317 134415 116405 246160 330613 267671    558   4759  45797\n",
      "  57282 383210 121308  96576 373100 116811     90  34495  53347  27292\n",
      "  73251 330058 248656 157346  10923  33618  34344 146760    552]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d781e5fed9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_point_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mblock_point_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_block_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_point_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}-{} is split into {} blocks.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "filename_txt = \"./data/arch/Test1/A_SMG_portico.txt\"\n",
    "print('{}-Loading {}...'.format(datetime.now(), filename_txt))\n",
    "all_data = np.loadtxt(filename_txt)\n",
    "xyzrgbl = all_data[:, 0:7]\n",
    "labels = xyzrgbl[:,-1]\n",
    "\n",
    "xyz = xyzrgbl[:,0:3]\n",
    "rgb = xyzrgbl[:,3:6] / 255 - 0.5\n",
    "block_size = 2.0\n",
    "offsets = [('zero', 0.0), ('half', block_size / 2)]\n",
    "print(offsets)\n",
    "for offset_name, offset in offsets:\n",
    "    print('{}-Computing block id of {} points...'.format(datetime.now(), xyzrgbl.shape[0]))\n",
    "    xyz_min = np.amin(xyz, axis=0, keepdims=True) - offset\n",
    "    xyz_max = np.amax(xyz, axis=0, keepdims=True)\n",
    "    print(\"xyz_min: \" + str(xyz_min))\n",
    "    print(\"xyz_max: \" + str(xyz_max))\n",
    "    block_size = (block_size, block_size, 2 * (xyz_max[0, -1] - xyz_min[0, -1]))\n",
    "    print(xyz_max[0, -1] - xyz_min[0, -1])\n",
    "    print(\"block_size: \" + str(block_size))\n",
    "    xyz_blocks = np.floor((xyz - xyz_min) / block_size).astype(np.int)\n",
    "    print(xyz_blocks)\n",
    "    print('{}-Collecting points belong to each block...'.format(datetime.now(), xyzrgbl.shape[0]))\n",
    "    blocks, point_block_indices, block_point_counts = np.unique(xyz_blocks, return_inverse=True, return_counts=True, axis=0)\n",
    "    print(blocks)\n",
    "    print(point_block_indices)\n",
    "    print(block_point_counts)\n",
    "    block_point_indices = np.split(np.argsort(point_block_indices), np.cumsum(block_point_counts[:-1]))\n",
    "    print('{}-{} is split into {} blocks.'.format(datetime.now(), dataset, blocks.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename, 'r')\n",
    "    data = f['data'][:]\n",
    "    label = f['label'][:]\n",
    "    data_num = f['data_num'][...].astype(np.int32)\n",
    "    labels_seg = f['label_seg'][...].astype(np.int64)\n",
    "    if 'indices_split_to_full' in f:\n",
    "        indices_split_to_full = f['indices_split_to_full'][...].astype(np.int64)\n",
    "    return (data, label, data_num, labels_seg, indices_split_to_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 8196, 6)\n",
      "(96, 8196)\n",
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "data_train, _, data_num_train, label_train, _ = load_h5(\"./data/arch/Train1/12_KAS_pavillion_1.txt_8192_half_0.h5\")\n",
    "print(data_train.shape)\n",
    "print(label_train.shape)\n",
    "print(data_num_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_seg(filelist):\n",
    "    points = []\n",
    "    labels = []\n",
    "    point_nums = []\n",
    "    labels_seg = []\n",
    "    indices_split_to_full = []\n",
    "\n",
    "    for fn in filelist:\n",
    "        data = h5py.File(fn, 'r')\n",
    "        points.append(data['data'][...].astype(np.float32))\n",
    "        labels.append(data['label'][...].astype(np.int64))\n",
    "        point_nums.append(data['data_num'][...].astype(np.int32))\n",
    "        labels_seg.append(data['label_seg'][...].astype(np.int64))\n",
    "        if 'indices_split_to_full' in data:\n",
    "            indices_split_to_full.append(data['indices_split_to_full'][...].astype(np.int64))\n",
    "\n",
    "    return (np.concatenate(points, axis=0),\n",
    "            np.concatenate(labels, axis=0),\n",
    "            np.concatenate(point_nums, axis=0),\n",
    "            np.concatenate(labels_seg, axis=0),\n",
    "            np.concatenate(indices_split_to_full, axis=0) if indices_split_to_full else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 8196, 6)\n",
      "(191, 8196)\n",
      "(191,)\n"
     ]
    }
   ],
   "source": [
    "filelist = [\"data/arch/Train1/12_KAS_pavillion_1.txt_8192_half_0.h5\",\"data/arch/Train1/12_KAS_pavillion_1.txt_8192_zero_0.h5\"]\n",
    "data_train, _, data_num_train, label_train, _ = load_seg(filelist)\n",
    "print(data_train.shape)\n",
    "print(label_train.shape)\n",
    "print(data_num_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-29 17:36:45.085651-Preparing datasets...\n",
      "./data/arch/./filelists/train_files_g_0.txt\n",
      "(8192, 2048, 6)\n",
      "(8192,)\n",
      "(8192, 2048)\n",
      "2020-10-29 17:36:45.708164-8192 training samples.\n",
      "2020-10-29 17:36:45.708325-174763 training batches.\n"
     ]
    }
   ],
   "source": [
    "# Prepare inputs\n",
    "import os.path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.append(os.path.join(\".\", 'utils'))\n",
    "import pc_utils\n",
    "\n",
    "\n",
    "filelist = \"./data/arch/train_data_files.txt\"\n",
    "batch_size = 12\n",
    "num_epochs = 256\n",
    "print('{}-Preparing datasets...'.format(datetime.now()))\n",
    "is_list_of_h5_list = not pc_utils.is_h5_list(filelist)\n",
    "if is_list_of_h5_list:\n",
    "    seg_list = pc_utils.load_seg_list(filelist)\n",
    "    seg_list_idx = 0\n",
    "    filelist_train = seg_list[seg_list_idx]\n",
    "    seg_list_idx = seg_list_idx + 1\n",
    "else:\n",
    "    filelist_train =  filelist\n",
    "print(filelist_train)\n",
    "data_train, _, data_num_train, label_train, _ = pc_utils.load_seg(filelist_train)\n",
    "print(data_train.shape)\n",
    "print(data_num_train.shape)\n",
    "print(label_train.shape)\n",
    "num_train = data_train.shape[0]\n",
    "point_num = data_train.shape[1]\n",
    "\n",
    "print('{}-{:d} training samples.'.format(datetime.now(), num_train))\n",
    "batch_num = (num_train * num_epochs + batch_size - 1) // batch_size\n",
    "print('{}-{:d} training batches.'.format(datetime.now(), batch_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Preparing datasets...\n",
      "segmentation files:36\n",
      "check paths length:/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/./filelists/train_files_g_0.txt\n",
      "Read datasets by load .h5 files\n",
      "size of all point_set: [(8192, 2048, 6),(8192, 2048)]\n",
      "dataloader size:  8192\n",
      "read point_set: [0]\n",
      "read point_set: [4]\n",
      "read point_set: [8]\n",
      "read point_set: [12]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [5]\n",
      "read point_set: [9]\n",
      "read point_set: [13]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [1]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [6]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [10]\n",
      "read point_set: [14]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [2]\n",
      "read point_set: [7]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [11]\n",
      "read point_set: [15]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [3]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [16]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [28]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [20]\n",
      "read point_set: [24]\n",
      "read point_set: [17]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [29]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [25]\n",
      "read point_set: [21]\n",
      "read point_set: [18]\n",
      "read point_set: [30]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [19]\n",
      "read point_set: [31]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [26]\n",
      "read point_set: [22]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [27]\n",
      "read point_set: [23]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "points:  torch.Size([4, 2048, 6]) <built-in method type of Tensor object at 0x7fbe9d9a3820>\n",
      "segs:  torch.Size([4, 2048]) <built-in method type of Tensor object at 0x7fbe9d9a37d0>\n",
      "read point_set: [32]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [33]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [34]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n",
      "read point_set: [35]\n",
      "point_set size: [torch.Size([2048, 6]),torch.Size([2048])]\n"
     ]
    }
   ],
   "source": [
    "!python ./datasets/dataloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = \"data/arch/train_data_files_1.txt\"\n",
    "path_h5py_all = [line.strip()for line in open(filelist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Preparing datasets...\n",
      "segmentation files:18\n",
      "check paths length:[]\n",
      "Read datasets by load .h5 files, filelist: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/./filelists/train_files_g_0.txt\n",
      "Load file: .././train/9_SMV_chapel_10.txt_2048_half_0.h5\n",
      "\n",
      "Load file: .././train/2_TR_church.txt_2048_zero_0.h5\n",
      "\n",
      "Load file: .././train/8_SMV_chapel_28.txt_2048_half_0.h5\n",
      "\n",
      "Load file: .././train/1_TR_cloister.txt_2048_zero_1.h5\n",
      "\n",
      "size of all point_set: [(3260, 8192, 6),(3260, 8192)]\n",
      "dataloader size:  3260\n",
      "read point_set: [4]\n",
      "read point_set: [8]\n",
      "read point_set: [0]\n",
      "read point_set: [12]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [1]\n",
      "read point_set: [9]\n",
      "read point_set: [5]\n",
      "read point_set: [13]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [2]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [14]\n",
      "read point_set: [10]\n",
      "read point_set: [6]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [3]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [15]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [11]\n",
      "read point_set: [7]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [20]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [16]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [28]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [21]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [24]\n",
      "read point_set: [17]\n",
      "read point_set: [29]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [22]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [18]\n",
      "read point_set: [30]\n",
      "read point_set: [25]\n",
      "read point_set: [23]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [26]\n",
      "read point_set: [31]\n",
      "read point_set: [19]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [27]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "points:  torch.Size([4, 8192, 6]) <built-in method type of Tensor object at 0x7f31109a05a0>\n",
      "segs:  torch.Size([4, 8192]) <built-in method type of Tensor object at 0x7f31109a0550>\n"
     ]
    }
   ],
   "source": [
    "!python ./datasets/dataloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename, 'r')\n",
    "    data = f['data'][...].astype(np.float32)\n",
    "    label = f['label_seg'][...].astype(np.int64)\n",
    "    return (data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 1.1700058e-01,  5.8587646e+00,  5.4479980e-01, -9.2156865e-02,\n",
       "          -4.5098040e-02,  5.8823531e-03],\n",
       "         [ 4.1160202e-01,  2.7543945e+00,  1.3759995e-01, -1.3529412e-01,\n",
       "          -1.4313726e-01, -1.5490197e-01],\n",
       "         [ 1.1501310e-02,  6.4817505e+00,  2.6469803e-01, -3.3921570e-01,\n",
       "          -3.0000001e-01, -2.3725490e-01],\n",
       "         ...,\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "        [[ 3.3010101e-01,  2.0324707e+00,  2.3180008e-01, -1.3137256e-01,\n",
       "          -1.4313726e-01, -1.7058824e-01],\n",
       "         [ 5.4759979e-01,  5.8562012e+00,  2.0209885e-01, -3.7843138e-01,\n",
       "          -3.7450981e-01, -3.5882354e-01],\n",
       "         [ 4.1301720e-02,  5.3617554e+00,  6.2489700e-01, -7.2549023e-02,\n",
       "          -4.1176472e-02, -1.9607844e-03],\n",
       "         ...,\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "        [[ 2.3569870e-01,  4.5488892e+00,  3.6739731e-01, -1.4705883e-01,\n",
       "          -1.4313726e-01, -1.5098040e-01],\n",
       "         [ 4.4039917e-01,  4.5959473e-01,  8.3099358e-02, -2.3333333e-01,\n",
       "          -1.9411765e-01, -1.5882353e-01],\n",
       "         [ 6.3399887e-01,  3.5872803e+00, -1.3339996e-01, -1.3137256e-01,\n",
       "          -1.3529412e-01, -1.3529412e-01],\n",
       "         ...,\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-4.3519783e-01,  3.4576416e-01,  5.4497528e-01, -2.6862746e-01,\n",
       "          -2.6470590e-01, -1.4313726e-01],\n",
       "         [-4.2577171e-01,  3.5473633e-01,  3.4729767e-01, -3.5098040e-01,\n",
       "          -3.1176472e-01, -2.2941177e-01],\n",
       "         [ 4.6841240e-01,  4.4140625e-01, -6.5182114e-01, -6.8627454e-02,\n",
       "          -6.0784314e-02, -4.5098040e-02],\n",
       "         ...,\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "        [[-2.5778008e-01,  2.3089600e-01,  2.1186066e-01, -2.8039217e-01,\n",
       "          -3.3529413e-01, -3.1568629e-01],\n",
       "         [-3.7119484e-01,  4.9664307e-01, -4.0075684e-01, -1.9019608e-01,\n",
       "          -1.5490197e-01, -9.6078433e-02],\n",
       "         [ 1.5952873e-01,  1.7456055e-01, -2.0170212e-01, -6.8627454e-02,\n",
       "          -1.9607844e-03,  1.0784314e-01],\n",
       "         ...,\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "        [[-1.1919975e-01,  5.2740479e-01, -5.6102756e-02, -2.8431374e-01,\n",
       "          -2.6470590e-01, -2.4901961e-01],\n",
       "         [ 1.1139489e-01,  3.4338379e-01,  1.5533066e-01, -3.0392158e-01,\n",
       "          -3.2745099e-01, -3.0000001e-01],\n",
       "         [ 1.0564995e-01,  5.1422119e-01,  1.5861893e-01, -3.6666667e-01,\n",
       "          -3.8235295e-01, -2.9215688e-01],\n",
       "         ...,\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "           0.0000000e+00,  0.0000000e+00]]], dtype=float32),\n",
       " array([[5, 5, 8, ..., 0, 0, 0],\n",
       "        [5, 4, 5, ..., 0, 0, 0],\n",
       "        [5, 5, 5, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [6, 6, 5, ..., 0, 0, 0],\n",
       "        [6, 6, 6, ..., 0, 0, 0],\n",
       "        [5, 5, 5, ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "load_h5(\"./data/arch/train/9_SMV_chapel_10.txt_2048_zero_0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"./datasets/gen_arch_h5.py\", line 106, in <module>\n",
      "    split_filelists[split] = ['%s/%s\\n' % (split, filename) for filename in os.listdir(os.path.join(root, split))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../data/arch/train'\n"
     ]
    }
   ],
   "source": [
    "!python ./datasets/gen_arch_h5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train/11_SStefano_portico_2.txt_2048_zero_0.h5\\n',\n",
       " 'train/1_TR_cloister.txt_2048_half_1.h5\\n',\n",
       " 'train/2_TR_church.txt_2048_half_0.h5\\n',\n",
       " 'train/1_TR_cloister.txt_2048_zero_0.h5\\n',\n",
       " 'train/3_VAL_room.txt_2048_zero_0.h5\\n',\n",
       " 'train/14_TRE_square.txt_2048_zero_0.h5\\n',\n",
       " 'train/4_CA_church.txt_2048_zero_0.h5\\n',\n",
       " 'train/10_SStefano_portico_1.txt_2048_zero_0.h5\\n',\n",
       " 'train/8_SMV_chapel_28.txt_2048_half_0.h5\\n',\n",
       " 'train/8_SMV_chapel_28.txt_2048_zero_0.h5\\n',\n",
       " 'train/13_KAS_pavillion_2.txt_2048_half_0.h5\\n',\n",
       " 'train/5_SMV_chapel_1.txt_2048_zero_0.h5\\n',\n",
       " 'train/9_SMV_chapel_10.txt_2048_zero_0.h5\\n',\n",
       " 'train/13_KAS_pavillion_2.txt_2048_zero_0.h5\\n',\n",
       " 'train/7_SMV_chapel_24.txt_2048_half_0.h5\\n',\n",
       " 'train/5_SMV_chapel_1.txt_2048_half_0.h5\\n',\n",
       " 'train/6_SMV_chapel_2to4.txt_2048_half_0.h5\\n',\n",
       " 'train/10_SStefano_portico_1.txt_2048_half_0.h5\\n',\n",
       " 'train/1_TR_cloister.txt_2048_zero_1.h5\\n',\n",
       " 'train/2_TR_church.txt_2048_zero_1.h5\\n',\n",
       " 'train/15_OTT_church.txt_2048_zero_0.h5\\n',\n",
       " 'train/1_TR_cloister.txt_2048_half_0.h5\\n',\n",
       " 'train/4_CA_church.txt_2048_half_0.h5\\n',\n",
       " 'train/3_VAL_room.txt_2048_half_0.h5\\n',\n",
       " 'train/2_TR_church.txt_2048_zero_0.h5\\n',\n",
       " 'train/14_TRE_square.txt_2048_half_0.h5\\n',\n",
       " 'train/6_SMV_chapel_2to4.txt_2048_zero_0.h5\\n',\n",
       " 'train/12_KAS_pavillion_1.txt_2048_zero_0.h5\\n',\n",
       " 'train/2_TR_church.txt_2048_half_1.h5\\n',\n",
       " 'train/12_KAS_pavillion_1.txt_2048_half_0.h5\\n',\n",
       " 'train/11_SStefano_portico_2.txt_2048_half_0.h5\\n',\n",
       " 'train/15_OTT_church.txt_2048_half_0.h5\\n',\n",
       " 'train/9_SMV_chapel_10.txt_2048_half_0.h5\\n',\n",
       " 'train/7_SMV_chapel_24.txt_2048_zero_0.h5\\n']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "root = './data/arch/'\n",
    "splits = ['train', 'test']\n",
    "split_filelists = dict()\n",
    "for split in splits:\n",
    "    split_filelists[split] = ['%s/%s\\n' % (split, filename) for filename in os.listdir(os.path.join(root, split))\n",
    "                                if filename.endswith('.h5')]\n",
    "\n",
    "train_h5 = split_filelists['train']\n",
    "random.shuffle(train_h5)\n",
    "train_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, dataset='arch', dropout=0.5, encoder='foldnet', epochs=248, eval=False, experiment_name=None, feat_dims=512, gpu_mode=False, k=None, model_path='', num_points=2048, snapshot_interval=10, split='train', use_jitter=False, use_rotate=False, use_translate=False, workers=16)\n",
      "-Preparing dataset file list...\n",
      "segmentation files:18\n",
      "-Preparing dataset...\n",
      "check paths length:[]\n",
      "Read datasets by load .h5 files, filelist: /home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/data/arch/./filelists/train_files_g_0.txt\n",
      "Load file: .././train/9_SMV_chapel_10.txt_2048_half_0.h5\n",
      "\n",
      "Load file: .././train/2_TR_church.txt_2048_zero_0.h5\n",
      "\n",
      "Load file: .././train/8_SMV_chapel_28.txt_2048_half_0.h5\n",
      "\n",
      "Load file: .././train/1_TR_cloister.txt_2048_zero_1.h5\n",
      "\n",
      "size of all point_set: [(3260, 8192, 6),(3260, 8192)]\n",
      "training set size:  3260\n",
      "validate set size: 3260\n",
      "training start!!!\n",
      "read point_set: [16]\n",
      "read point_set: [0]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [17]\n",
      "read point_set: [1]\n",
      "read point_set: [32]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [33]\n",
      "read point_set: [18]\n",
      "read point_set: [2]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [34]\n",
      "read point_set: [19]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [3]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [35]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [20]\n",
      "read point_set: [48]\n",
      "read point_set: [4]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [36]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [5]\n",
      "read point_set: [37]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [49]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [38]\n",
      "read point_set: [6]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [50]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [39]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [7]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [51]\n",
      "read point_set: [21]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [40]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [8]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [52]\n",
      "read point_set: [41]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [22]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [9]\n",
      "read point_set: [42]\n",
      "read point_set: [53]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [23]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [43]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [10]\n",
      "read point_set: [54]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [24]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [44]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [11]\n",
      "read point_set: [55]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [45]\n",
      "read point_set: [25]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [12]\n",
      "read point_set: [56]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [46]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [26]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [13]\n",
      "read point_set: [47]\n",
      "read point_set: [57]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [27]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [14]\n",
      "read point_set: [58]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [28]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [15]\n",
      "read point_set: [59]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [29]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [60]\n",
      "read point_set: [30]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [61]\n",
      "read point_set: [31]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [62]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [63]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [64]\n",
      "read point_set: [80]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [81]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [65]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [82]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [83]\n",
      "read point_set: [66]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [84]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [67]\n",
      "read point_set: [85]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [86]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [68]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [96]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [87]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [69]\n",
      "read point_set: [97]\n",
      "read point_set: [88]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [89]\n",
      "read point_set: [98]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [70]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [99]\n",
      "read point_set: [90]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [71]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [91]\n",
      "read point_set: [100]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [72]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [92]\n",
      "read point_set: [101]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [73]\n",
      "read point_set: [93]\n",
      "read point_set: [112]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [102]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [94]\n",
      "read point_set: [74]\n",
      "read point_set: [103]\n",
      "read point_set: [113]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [95]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [104]\n",
      "read point_set: [75]\n",
      "read point_set: [114]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [105]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [115]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [106]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [116]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [107]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [117]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [108]\n",
      "read point_set: [118]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [109]\n",
      "read point_set: [119]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [110]\n",
      "read point_set: [120]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [111]\n",
      "read point_set: [121]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [122]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [123]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [124]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [76]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [125]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [77]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [126]\n",
      "read point_set: [144]\n",
      "read point_set: [78]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [127]\n",
      "read point_set: [79]\n",
      "read point_set: [145]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [146]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [128]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [147]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [148]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [129]\n",
      "read point_set: [149]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [150]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [130]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [151]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [152]\n",
      "read point_set: [131]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [153]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [154]\n",
      "read point_set: [132]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [155]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [160]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [156]\n",
      "read point_set: [133]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [161]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [157]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [162]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [158]\n",
      "read point_set: [134]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [163]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [159]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [135]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [164]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [136]\n",
      "read point_set: [165]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [137]\n",
      "read point_set: [166]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [167]\n",
      "read point_set: [138]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [168]\n",
      "read point_set: [139]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [169]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [140]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [170]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [141]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [171]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [142]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [172]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [143]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [173]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [174]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [175]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [176]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [177]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [178]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [179]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [180]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [181]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [182]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [183]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [184]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [185]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [186]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [187]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [188]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [189]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [190]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [191]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [224]\n",
      "read point_set: [208]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [192]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [225]\n",
      "read point_set: [209]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [226]\n",
      "read point_set: [210]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [227]\n",
      "read point_set: [211]\n",
      "read point_set: [193]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [228]\n",
      "read point_set: [212]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [194]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [229]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [195]\n",
      "read point_set: [213]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [230]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [196]\n",
      "read point_set: [214]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [256]\n",
      "read point_set: [231]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [197]\n",
      "read point_set: [257]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [215]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [232]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [258]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [216]\n",
      "read point_set: [233]\n",
      "read point_set: [259]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [198]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [260]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [217]\n",
      "read point_set: [234]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [199]\n",
      "read point_set: [261]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [235]\n",
      "read point_set: [218]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [200]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [236]\n",
      "read point_set: [219]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [288]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [237]\n",
      "read point_set: [220]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [289]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [238]\n",
      "read point_set: [320]\n",
      "read point_set: [221]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [290]\n",
      "read point_set: [321]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [222]\n",
      "read point_set: [239]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [291]\n",
      "read point_set: [336]\n",
      "read point_set: [322]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [240]\n",
      "read point_set: [223]\n",
      "read point_set: [323]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [292]\n",
      "read point_set: [337]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [324]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [241]\n",
      "read point_set: [293]\n",
      "read point_set: [325]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [338]\n",
      "read point_set: [242]\n",
      "read point_set: [294]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [295]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [201]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [296]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [352]\n",
      "read point_set: [297]\n",
      "read point_set: [243]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [202]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [244]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [245]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [203]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [246]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [247]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [204]\n",
      "read point_set: [248]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [249]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [205]\n",
      "read point_set: [250]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [272]\n",
      "read point_set: [251]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [206]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [273]\n",
      "read point_set: [252]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [253]\n",
      "read point_set: [274]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [207]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [254]\n",
      "read point_set: [304]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [275]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [255]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [276]\n",
      "read point_set: [305]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [306]\n",
      "read point_set: [277]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [278]\n",
      "read point_set: [307]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [279]\n",
      "read point_set: [308]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [309]\n",
      "read point_set: [280]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [310]\n",
      "read point_set: [281]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [311]\n",
      "read point_set: [282]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [283]\n",
      "read point_set: [312]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [284]\n",
      "read point_set: [313]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [285]\n",
      "read point_set: [314]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [315]\n",
      "read point_set: [286]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [316]\n",
      "read point_set: [287]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [317]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [318]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [319]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [339]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [262]\n",
      "read point_set: [340]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [263]\n",
      "read point_set: [341]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [342]\n",
      "read point_set: [264]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [343]\n",
      "read point_set: [265]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [266]\n",
      "read point_set: [344]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [345]\n",
      "read point_set: [267]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [346]\n",
      "read point_set: [268]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [347]\n",
      "read point_set: [269]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [348]\n",
      "read point_set: [270]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [349]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [271]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [350]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [351]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [368]\n",
      "read point_set: [400]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [401]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [402]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [369]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [403]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [404]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [370]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [405]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [353]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [406]\n",
      "read point_set: [354]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [371]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [407]\n",
      "read point_set: [355]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [356]\n",
      "read point_set: [408]\n",
      "read point_set: [372]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [357]\n",
      "read point_set: [409]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [358]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [410]\n",
      "read point_set: [373]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [359]\n",
      "read point_set: [326]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [411]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [360]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [374]\n",
      "read point_set: [412]\n",
      "read point_set: [327]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [361]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [413]\n",
      "read point_set: [362]\n",
      "read point_set: [328]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [375]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [414]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [329]\n",
      "read point_set: [363]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [415]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [376]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [330]\n",
      "read point_set: [364]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [331]\n",
      "read point_set: [480]\n",
      "read point_set: [365]\n",
      "read point_set: [377]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [332]\n",
      "read point_set: [366]\n",
      "read point_set: [481]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [378]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [333]\n",
      "read point_set: [448]\n",
      "read point_set: [367]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [482]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [334]\n",
      "read point_set: [379]\n",
      "read point_set: [449]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [483]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [335]\n",
      "read point_set: [450]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [484]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [451]\n",
      "read point_set: [485]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [452]\n",
      "read point_set: [486]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [453]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [487]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [454]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [416]\n",
      "read point_set: [488]\n",
      "read point_set: [432]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [433]\n",
      "read point_set: [417]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [434]\n",
      "read point_set: [418]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [419]\n",
      "read point_set: [435]\n",
      "read point_set: [489]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [420]\n",
      "read point_set: [436]\n",
      "read point_set: [490]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [421]\n",
      "read point_set: [437]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [491]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [422]\n",
      "read point_set: [438]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [492]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [423]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [439]\n",
      "read point_set: [493]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [424]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [440]\n",
      "read point_set: [494]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [425]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [441]\n",
      "read point_set: [495]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [426]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [442]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [427]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [443]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [428]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [444]\n",
      "read point_set: [429]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [445]\n",
      "read point_set: [430]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [446]\n",
      "read point_set: [431]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [447]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [298]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [299]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [300]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [301]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [302]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [303]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [380]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [384]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [385]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [386]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [387]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [388]\n",
      "read point_set: [381]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [389]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [390]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [391]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [382]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [392]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [393]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [394]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [383]\n",
      "read point_set: [395]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [396]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [397]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [398]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [399]\n",
      "read point_set: [455]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [456]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [457]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [464]\n",
      "read point_set: [458]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [465]\n",
      "read point_set: [459]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [466]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [467]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [468]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [496]\n",
      "read point_set: [469]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [497]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [470]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [498]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [471]\n",
      "read point_set: [499]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [500]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [460]\n",
      "read point_set: [472]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [501]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [473]\n",
      "read point_set: [461]\n",
      "read point_set: [502]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [503]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [474]\n",
      "read point_set: [462]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [504]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [475]\n",
      "read point_set: [505]\n",
      "read point_set: [463]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [506]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [476]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [507]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [477]\n",
      "read point_set: [508]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [509]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [478]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [510]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [479]\n",
      "read point_set: [511]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [512]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [513]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [514]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [515]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [516]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [517]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [518]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [519]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [520]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [521]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [522]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [523]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [524]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [525]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [526]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "read point_set: [527]\n",
      "point_set size: [torch.Size([8192, 6]),torch.Size([8192])]\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 79, in <module>\n",
      "    reconstruction.train()\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/trainer.py\", line 159, in train\n",
      "    loss = self.train_epoch(epoch)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/trainer.py\", line 208, in train_epoch\n",
      "    output, _ = self.model(pts)\n",
      "  File \"/home/yw/anaconda3/envs/PyTorch1.2/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/model.py\", line 474, in forward\n",
      "    feature = self.encoder(input)\n",
      "  File \"/home/yw/anaconda3/envs/PyTorch1.2/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/model.py\", line 168, in forward\n",
      "    idx = knn(pts, k=self.k)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/model.py\", line 41, in knn\n",
      "    inner = -2*torch.matmul(x.transpose(2,1),x)\n",
      "RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 4294967296 bytes. Error code 12 (Cannot allocate memory)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 2048, 3)\n",
      "dataloader size:  35708\n",
      "points:  torch.Size([4, 2048, 3]) <built-in method type of Tensor object at 0x7f00641f97d0>\n",
      "segs:  torch.Size([4, 1]) <built-in method type of Tensor object at 0x7f00641f9780>\n"
     ]
    }
   ],
   "source": [
    "!python ./datasets/shapenet_dataloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, dataset='shapenetcorev2', dropout=0.5, encoder='foldnet', epochs=248, eval=False, experiment_name=None, feat_dims=512, gpu_mode=False, k=None, model_path='', num_points=2048, snapshot_interval=10, split='train', use_jitter=False, use_rotate=False, use_translate=False, workers=16)\n",
      "-Preparing dataset...\n",
      "-Loading ShapeNetCore dataset...\n",
      "(2048, 2048, 3)\n",
      "training set size:  35708\n",
      "training start!!!\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 79, in <module>\n",
      "    reconstruction.train()\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/trainer.py\", line 166, in train\n",
      "    loss = self.train_epoch(epoch)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/trainer.py\", line 215, in train_epoch\n",
      "    output, _ = self.model(pts)\n",
      "  File \"/home/yw/anaconda3/envs/PyTorch1.2/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/model.py\", line 474, in forward\n",
      "    feature = self.encoder(input)\n",
      "  File \"/home/yw/anaconda3/envs/PyTorch1.2/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/model.py\", line 169, in forward\n",
      "    x = local_cov(pts, idx) #(batch_size, 6, num_points) -> (batch_size, 12, num_points)\n",
      "  File \"/home/yw/Documents/experiment/Unsupervised-learning-on-LoD3-building-point-cloud/model/model.py\", line 77, in local_cov\n",
      "    x = torch.cat((pts, x), dim=1)                          # (batch_size, 12, num_points)\n",
      "RuntimeError: Tensors must have same number of dimensions: got 3 and 4\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
